**Localhost: Use the same network namespace
**For containers, the observable host name is a Pod's name. Because containers share the same IP address and port space, 
you should use different ports in containers for incoming connections.
**Pod: Represents a running set of containers in your cluster.


Cluster Networking:
Four distinct networking problems:
1) Highly-coupled containter-to-container communications: this is solved by Pods and localhost communications
2) Pod-to-Pod communications
3) Pod-to-Service communication
4) External-to-Service communications

**Kubernetes is all about sharing machines between applications. Typically, sharing machines requires ensuring that two
applications do not try to use the same ports. Coordinating ports across multiple developers is very difficult to do at scale
and exposes users to cluster-level issues outside of their control.

//Not the kubernetes network model
**Dynamic port allocation brings a lot of complications to the system - every application has to take ports as flags, the API
servers have to know how to insert dynamic port numbers into configuration blocks, services have to know how to find each otherm, etc.

//The Kubernetes network model
**Every "Pod" gets its own IP address. This means you do not need to explicity create links between Pods and you almost never need to
deal with mapping container ports to host ports. This creates a clean, backwards-compatible model where Pods can be treated much like 
VM's or physical hosts from the perspective of port allocation, naming, service discovery, load balancing, application configuration,
and migration.

**Kubernetes imposes the following fundamental *requirements* on any networking implementation (barring any international network segmentation
policies):
- Pods on a node can communicate with all pods on all nodes without NAT
- Agents on a node (e.g. system daemons, kubelet) can communicate with all pods on that node.

***Note: For those platforms that support Pods running in the host network (e.g Linux):
- Pods in the host network of a node can communicate with all pods on all nodes without NAT.

**This process allows for low-friction porting of apps from VM's to containers. Similar model: If your job previously ran in a
VM, your VM had an IP and could talk to other VM's in your project. 

// IP-per-Pod Model
Kubernetes IP addresses exist at the Pod scope - containers within a Pod share their network namespaces - including their IP address.
This means that containers within a Pod can all reach each other's ports on "localhost". This also means that containers within a Pod 
must coordinate port usage, but this is no different from processes in a VM.

** It is possible to request ports on the Node itself which forward to your Pod (called host ports), but this is a very niche operation.
How that forwarding is implemented is also a detail of the container runtime. The Pod itself is blind to the existence or non-existence of 
host ports.


/* Implementation of the Kubernetes Network Model */
Netoworking options such as:
ACI: Cisco Application Centric Infrastructure.
GCE: Google Compute Engine.
AWS VPC CNI: AWS Virtual Private cloud
Azure CNI






//
Ports:
If you set the "type" field to NodePort, the Kubernetes control plane allocated a port from a range specificed by 
"--service-node-port-range" flag (default: 30000-32767). Each node proxies that port (the same port number on each Node)
into your service. Your service reports the allocated port in its ".spec.ports[*].nodePort" field.

If you want to specify a particular IP(s) to proxy the port, you can set the "--nodeport-addresses" flag in kube-proxy to 
particular IP block(s); this is supported since Kubernetes v1.10. This flag takes a comma-delimited list of IP blocks 
(e.g 10.0.0.0/8, 192.0.2.0/25) to specify IP address ranges that kube-proxy should consider as local to this node.

